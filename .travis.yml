# See https://github.com/JLLeitschuh/shuffleboard/commit/445eabb6234f7973351acfb492123484491e2008 for Docker cache

sudo: required
dist: trusty
language: generic

branches:
  except:
    - gh-pages

services:
  - docker

addons:
  apt:
    packages:
      - docker-ce

env:
  global:
    - HUGO_VERSION=0.48
    - HUGO_HASH=9830ee1d51f225beb31ac2855cbc269048e1d3b75f8d5e70afe5eb44ad78f9ad

before_install:
  # Set to fail on errors
  - set -o errexit && set -o pipefail
  # Build docker container
  - if [[ -d ${HOME}/docker ]]; then
      find "${HOME}/docker" -name '*.tar.gz' -print0 | xargs -0 --no-run-if-empty -I {file} sh -c "zcat {file} | docker load";
    fi
  - docker build --build-arg=HUGO_VERSION --build-arg=HUGO_HASH --label=cache-travis=true --tag hugo-base --target base .travis
  - docker build --build-arg=HUGO_VERSION --build-arg=HUGO_HASH --label=cache-travis=true --tag hugo-builder --target builder .travis
  - docker build --build-arg=HUGO_VERSION --build-arg=HUGO_HASH --label=cache-travis=true --tag hugo .travis
  # Install AWS CLI
  - pip install --user --upgrade pip
  - pip install --user --upgrade awscli
  - export PATH="${HOME}/.local/bin:${PATH}"
  # Reset shell
  - set +o errexit && set +o pipefail

jobs:
  include:
    # Build site to test it works
    - stage: Test
      script:
        - docker run -v "${PWD}:/repo" hugo

    # Add archive of site to GitHub via releases
    - stage: Archive
      if: branch = master
      script:
        - docker run -v "${PWD}:/repo" hugo
        - sudo chown -R travis:travis site/public
      before_deploy:
        - tar -czvf public.tar.gz site/public
      deploy:
        provider: releases
        api_key: ${GITHUB_TOKEN}
        file: public.tar.gz
        skip_cleanup: true

    # Upload to S3 for public CDN
    - stage: Deploy
      if: branch = master
      script:
        - docker run -v "${PWD}:/repo" hugo
        - sudo chown -R travis:travis site/public
      deploy:
        provider: s3
        access_key_id: "${AWS_ACCESS_KEY}"
        secret_access_key: "${AWS_SECRET_KEY}"
        bucket: "com.thebiggerguy.www"
        region: eu-west-1
        acl: private
        local_dir: site/public
        skip_cleanup: true
      after_deploy:
        - awd cloudfront create-invalidation --distribution-id "${AWS_CLOUDFRONT_DISTRIBUTION_ID}"

before_cache:
  # Cache Docker files
  - mkdir -p "${HOME}/docker"
  - echo 'Docker images with cache-travis=true' && docker images --all --filter='dangling=false' --filter='label=cache-travis=true' --format '{{.Repository}}:{{.Tag}} {{.ID}}'
  - echo 'Docker images in cache' && find "${HOME}/docker/" -name '*.tar.gz'
  - >
    docker images --all --filter='dangling=false' --filter='label=cache-travis=true' --format '{{.Repository}}:{{.Tag}} {{.ID}}'
    | xargs -n 2 -t sh -c 'test -e "${HOME}/docker/${1}.tar.gz" || docker save "${0}" | gzip -2 > "${HOME}/docker/${1}.tar.gz"'
  # Clean cached Docker files after 30 days
  - find "${HOME}/docker" -type f -mtime +30 -exec rm {} \;

cache:
  directories:
    - ${HOME}/.local
    - ${HOME}/docker
